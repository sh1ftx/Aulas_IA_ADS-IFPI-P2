{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Práticas iniciais com pandas."
      ],
      "metadata": {
        "id": "WfDB88Hr2Zu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DLc47B21HkN"
      },
      "outputs": [],
      "source": [
        "print(\"Testando a versão do pandas.\")\n",
        "import pandas as pd #importa a biblioteca com o alias  pd\n",
        "print(pd.__version__)\n",
        "from  google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "print(\"Exibindo um arquivo  .CSV\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/world_happiness_report_2015.csv\")\n",
        "#Praticas\n",
        "#print(df.describe(include=\"all\"))\n",
        "print(\"Exibindo o formato dos dados:\")\n",
        "print(df.shape)\n",
        "#print(df.head())\n",
        "#print(df.columns)\n",
        "df.columns = ['Country', 'Region', 'rank_felicidade', 'score_felicidade',\n",
        "       'stand_error', 'PIB', 'Family',\n",
        "       'expect_vida', 'Freedom', 'corrupcao',\n",
        "       'Generosity', 'Dystopia Residual']\n",
        "#print(df.columns)\n",
        "print()\n",
        "print(df.info())\n",
        "#X = df.loc[ : , 'Country':'Generosity']\n",
        "#print(X.describe())\n",
        "#print(X.shape)\n",
        "#y = df['Dystopia Residual']\n",
        "#print(y.shape)\n",
        "df['Country'] = df['Country'].astype('category')\n",
        "df['class'] = df['Country'].cat.codes\n",
        "#print(df.info())\n",
        "#print(df.head())\n",
        "#print(df['Region'].head(15))\n",
        "df['Region'] = df['Region'].astype('category')\n",
        "df['class1'] = df['Region'].cat.codes\n",
        "print(df.info())\n",
        "print(df['class1'].head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nova célula"
      ],
      "metadata": {
        "id": "bUpAwVGVMCLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testando a versão do pandas.\")\n",
        "import pandas as pd #importa a biblioteca com o alias  pd\n",
        "print(pd.__version__)\n",
        "from  google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "print(\"Exibindo um arquivo  .CSV\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/world_happiness_report_2015.csv\")\n",
        "#Praticas\n",
        "#print(df.describe(include=\"all\"))\n",
        "print(\"Exibindo o formato dos dados:\")\n",
        "print(df.shape)\n",
        "#print(df.head())\n",
        "#print(df.columns)\n",
        "df.columns = ['Country', 'Region', 'rank_felicidade', 'score_felicidade',\n",
        "       'stand_error', 'PIB', 'Family',\n",
        "       'expect_vida', 'Freedom', 'corrupcao',\n",
        "       'Generosity', 'Dystopia Residual']\n",
        "print(df.info())\n",
        "#X = df.loc[ : , 'Country':'Generosity']\n",
        "#print(X.describe())\n",
        "#print(X.shape)\n",
        "#y = df['Dystopia Residual']\n",
        "#print(y.shape)\n",
        "df['Country'] = df[\"Country\"].astype('category') #converte a coluna existente\n",
        "df['classes'] = df[\"Country\"].cat.codes #cria a nova coluna c om os codigos\n",
        "#print(df.info())\n",
        "print(df['classes'].head()) #mostra os primeiros itens da coluna\n"
      ],
      "metadata": {
        "id": "3U4gwnuyMGQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testando a versão do pandas.\")\n",
        "import pandas as pd #importa a biblioteca com o alias  pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder #encoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(pd.__version__)\n",
        "from  google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "print(\"Exibindo um arquivo  .CSV\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/iris.csv\")\n",
        "df.columns = ['sepal_length', 'sepal_width','petal_length', 'petal_width', 'class']\n",
        "#Praticas\n",
        "print(df.columns)\n",
        "#print(df.info())\n",
        "#df['class'] = df[\"class\"].astype('category') #converte a coluna existente\n",
        "#df['class1'] = df[\"class\"].cat.codes #cria a nova coluna c om os codigos\n",
        "#print(df.info())\n",
        "X = df.loc[: ,'sepal_length': 'petal_width']\n",
        "y = df['class']\n",
        "\n",
        "#Exibe as dimensões\n",
        "print(X.shape, y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) #Exibe dimensões\n",
        "#fit the model\n",
        "model = RandomForestClassifier( ) #cria uma variável model para o classificador\n",
        "enc = LabelEncoder()\n",
        "y_train = enc.fit_transform(y_train) #treina o encoder\n",
        "model.fit(X_train, y_train) #treina o modelo\n",
        "yhat = model.predict(X_test)#realiza predições nas entradas de teste\n",
        "#avalia as predictions\n",
        "y_test = enc.transform(y_test) #transforma os dados novos\n",
        "acc = accuracy_score(y_test, yhat) #compara o predito com o real contido em y_test\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "id": "oa8V6TRi1tNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testando a versão do pandas.\")\n",
        "import pandas as pd #importa a biblioteca com o alias  pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder #encoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(pd.__version__)\n",
        "from  google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "print(\"Exibindo um arquivo  .CSV\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/crx.csv\") #Carregamos o dataset em uma variável df\n",
        "#Aqui teremos algumas dicas e lembretes como comentários sobre comandos de pré-processamento\n",
        "#Mostrar um resumo das  estatísticas incluindo dados categórigos\n",
        "#Exemplo --> df.describe(include=\"all\"\n",
        "#Mostrar tipos de dados das colunas em conjunto com informações de valores nulos\n",
        "#Exemplo --> df.info()\n",
        "#Mostrar quantos valores nulos foram encontrados\n",
        "#Exemplo -->  df.isnull().sum()  ou podemos usar   df.isnull().sum().sort_values(ascending=False)[:15]\n",
        "#Remove todas as linhas que possuem QUALQUER item nulo\n",
        "#Exemplo --> df.dropna(axis=0, inplace=True)\n",
        "#Substitui valores nulos por um valor específico/fixo apenas na coluna e local dos nulos (deve ser feito em cada coluna com nulo)\n",
        "#Exemplo --> df[\"nome_da_coluna\"].fillna(\"Novo_valor\", inplace=True)\n",
        "#Substitui os valores nulos de uma coluna especifica pela frequencia (valor que mais se repete) ou média ou qualquer medida estística\n",
        "#     maisfrequente = df[\"nome_da_coluna\"].value_counts()[0]\n",
        "#     df[\"nome_da_coluna\"].fillna(maisfrequente, inplace=True)\n",
        "#Contando valores específicos para detectar anomalias\n",
        "#Exemplo -->  df[\"nome_da_coluna\"].value_counts()\n",
        "#Substituindo valores específicos usando uma condição\n",
        "#Exemplo -->   df.loc[df['nome_da_coluna'] == 'valor_a_ser_alterado', 'nome_da_coluna'] = 'novo_valor'\n",
        "#Substituindo valores específicos usando mask\n",
        "#Exemplo --> df['nome_da_coluna'].mask(df['nome_da_coluna'] == 'valor_a_ser_alterado', 'novo_valor', inplace=True)\n",
        "#Removendo todas as linhas com um valor específico:\n",
        "#Exemplo --> df = df.drop(df[df['nome_da_coluna'] == 'valor_a_remover'].index)\n",
        "#Obs: Existe uma forma avançada de substituir  valores no pandas com funções lambda e .apply para casos mais especĩficos.\n",
        "#Agora vamos usar um pouco do que vimos em um dataser real:\n",
        "#print(df.info()) #Visualizando as colunas\n",
        "#print(df.describe(include=\"all\")) #Visualizando as estatísticas\n",
        "print(\"Contagem A2: \", df[\"A2\"].value_counts()) #Contando valores específicos para identificar anomalias\n",
        "#Substituindo os valores da coluna  A4  por t\n",
        "colunas = ['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11',\n",
        "           'A12','A13','A14','A15','A16']\n",
        "for c in colunas:\n",
        "  #print(\"Alterando a coluna \",c)\n",
        "  df = df.drop(df[df[c] == '?'].index)\n",
        "#Fim do loop\n",
        "print(df.info())\n",
        "#Separamos as colunas para as variáveis de entrada  X e para a saída  y\n",
        "X = df.loc[:, \"A1\":\"A15\"]\n",
        "y = df[\"A16\"]\n",
        "print(X.shape , y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "#print(X_train.describe())\n",
        "encA1 = OrdinalEncoder()\n",
        "encA2 = OrdinalEncoder()\n",
        "encA4 = OrdinalEncoder()\n",
        "encA5 = OrdinalEncoder()\n",
        "encA6 = OrdinalEncoder()\n",
        "encA7 = OrdinalEncoder()\n",
        "encA9 = OrdinalEncoder()\n",
        "encA10 = OrdinalEncoder()\n",
        "encA12 = OrdinalEncoder()\n",
        "encA13 = OrdinalEncoder()\n",
        "encA14 = OrdinalEncoder()\n",
        "encA16 = LabelEncoder()\n",
        "#Fit_transform\n",
        "X_train['A1'] = encA1.fit_transform(X_train[[\"A1\"]])\n",
        "X_train['A4'] = encA4.fit_transform(X_train[[\"A4\"]])\n",
        "X_train['A5'] = encA5.fit_transform(X_train[[\"A5\"]])\n",
        "X_train['A6'] = encA6.fit_transform(X_train[[\"A6\"]])\n",
        "X_train['A7'] = encA7.fit_transform(X_train[[\"A7\"]])\n",
        "X_train['A9'] = encA9.fit_transform(X_train[[\"A9\"]])\n",
        "X_train['A10'] = encA10.fit_transform(X_train[[\"A10\"]])\n",
        "X_train['A12'] = encA12.fit_transform(X_train[[\"A12\"]])\n",
        "X_train['A13'] = encA13.fit_transform(X_train[[\"A13\"]])\n",
        "y_train = encA16.fit_transform(y_train)\n",
        "#Treinamento do algoritmo\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "#Transform do teste\n",
        "X_test['A1'] = encA1.transform(X_test[[\"A1\"]])\n",
        "X_test['A4'] = encA4.transform(X_test[[\"A4\"]])\n",
        "X_test['A5'] = encA5.transform(X_test[[\"A5\"]])\n",
        "X_test['A6'] = encA6.transform(X_test[[\"A6\"]])\n",
        "X_test['A7'] = encA7.transform(X_test[[\"A7\"]])\n",
        "X_test['A9'] = encA9.transform(X_test[[\"A9\"]])\n",
        "X_test['A10'] = encA10.transform(X_test[[\"A10\"]])\n",
        "X_test['A12'] = encA12.transform(X_test[[\"A12\"]])\n",
        "X_test['A13'] = encA13.transform(X_test[[\"A13\"]])\n",
        "y_test = encA16.transform(y_test)\n",
        "#avaliacao do modelo\n",
        "yhat = model.predict(X_test)\n",
        "acc = accuracy_score(yhat , y_test)\n",
        "print(\"A acuracia foi: \", (acc * 100))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jlqlyDBhBg",
        "outputId": "9c39bfb8-e50c-4f26-cdab-2f95fabcbd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando a versão do pandas.\n",
            "2.2.2\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Exibindo um arquivo  .CSV\n",
            "Contagem A2:  A2\n",
            "?        12\n",
            "22.67     9\n",
            "20.42     7\n",
            "25.00     6\n",
            "20.67     6\n",
            "         ..\n",
            "30.33     1\n",
            "47.17     1\n",
            "25.83     1\n",
            "50.25     1\n",
            "36.42     1\n",
            "Name: count, Length: 350, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 653 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      653 non-null    object \n",
            " 1   A2      653 non-null    object \n",
            " 2   A3      653 non-null    float64\n",
            " 3   A4      653 non-null    object \n",
            " 4   A5      653 non-null    object \n",
            " 5   A6      653 non-null    object \n",
            " 6   A7      653 non-null    object \n",
            " 7   A8      653 non-null    float64\n",
            " 8   A9      653 non-null    object \n",
            " 9   A10     653 non-null    object \n",
            " 10  A11     653 non-null    int64  \n",
            " 11  A12     653 non-null    object \n",
            " 12  A13     653 non-null    object \n",
            " 13  A14     653 non-null    object \n",
            " 14  A15     653 non-null    int64  \n",
            " 15  A16     653 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.7+ KB\n",
            "None\n",
            "(653, 15) (653,)\n",
            "(522, 15) (131, 15) (522,) (131,)\n",
            "A acuracia foi:  89.31297709923665\n"
          ]
        }
      ]
    }
  ]
}